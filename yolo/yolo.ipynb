{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Definimos el bloque convolucional",
   "id": "72ce48f75cfeea77"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T02:32:43.244824Z",
     "start_time": "2025-05-09T02:32:43.240855Z"
    }
   },
   "source": [
    "from sched import scheduler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def conv_block(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    return nn.Sequential(\n",
    "       nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.1)\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creámos nuestra red YoloV1",
   "id": "7c67ca3721aec0ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T02:46:15.463636Z",
     "start_time": "2025-05-09T02:46:15.456483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Yolo(nn.Module):\n",
    "    def __init__(self, s=7,b=2, c=1):\n",
    "        super(Yolo, self).__init__()\n",
    "        self.s = s\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.layers=[self.layer1(),self.layer2(),self.layer3(),self.layer4(), self.layer5(),self.layer6()]\n",
    "        self.features = nn.Sequential(*self.layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024*self.s*self.s,4096),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(4096,self.s*self.s*(self.c+self.b*5)),\n",
    "\n",
    "        )\n",
    "    def layer1(self):\n",
    "        return nn.Sequential(\n",
    "            conv_block(3,64,7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "    def layer2(self):\n",
    "        return nn.Sequential(\n",
    "            conv_block(64,192,3,padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "    def layer3(self):\n",
    "        return nn.Sequential(\n",
    "            conv_block(192,128,1),\n",
    "            conv_block(128,256,3, padding=1),\n",
    "            conv_block(256,256,1),\n",
    "            conv_block(256,512,3, padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "    def layer4(self):\n",
    "        blocks=[\n",
    "            nn.Sequential(\n",
    "                conv_block(512,256,1),\n",
    "                conv_block(256,512,3, padding=1),\n",
    "            ) for _ in range(4)\n",
    "        ]\n",
    "        return nn.Sequential(\n",
    "            *blocks,\n",
    "            conv_block(512,512,1),\n",
    "            conv_block(512,1024,3, padding=1),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "    def layer5(self):\n",
    "        blocks=[\n",
    "            nn.Sequential(\n",
    "                conv_block(1024,512,1),\n",
    "                conv_block(512,1024,3, padding=1),\n",
    "            ) for _ in range(2)\n",
    "        ]\n",
    "        return nn.Sequential(\n",
    "            *blocks,\n",
    "            conv_block(1024,1024,3, padding=1),\n",
    "            conv_block(1024,1024,3, stride=2, padding=1)\n",
    "        )\n",
    "    def layer6(self):\n",
    "        return nn.Sequential(\n",
    "            conv_block(1024,1024,3, padding=1),\n",
    "            conv_block(1024,1024,3, padding=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x=self.features(x)\n",
    "        x=self.classifier(x)\n",
    "        return x.view(-1, self.s, self.s, self.c+self.b*5)"
   ],
   "id": "1edba11e85330f4f",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DATA LOADER",
   "id": "bae9ecceaae18bff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T02:46:21.680479Z",
     "start_time": "2025-05-09T02:46:21.673464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, img_dir,label_dir, S=7, B=2, C=1 ):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.transform = transforms.Compose([transforms.Resize((448, 448)),transforms.ToTensor()])\n",
    "        #[\"tumor1.jpg\",\"tumor2.png\".....]\n",
    "        self.image_filenames=[f for f in os.listdir(self.img_dir) if f.endswith('.jpg') or f.endswith('.png') ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.image_filenames[idx]\n",
    "        image_path=os.path.join(self.img_dir, image_filename)\n",
    "        label_path=os.path.join(self.label_dir,image_filename.replace('.jpg','.txt').replace('.png','.txt'))\n",
    "        image=Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label_tensor=torch.zeros((self.S,self.S,self.C+self.B*5))\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path) as f:\n",
    "                for line in f.readlines():\n",
    "                    class_id, x,y,w,h=map(float,line.strip().split())\n",
    "                    i=int(x*self.S)\n",
    "                    j=int(y*self.S)\n",
    "                    x_cell=x*self.S-1\n",
    "                    y_cell=y*self.S-1\n",
    "                    w_cell=w\n",
    "                    h_cell=h\n",
    "                    if label_tensor[j,i,self.C]==0:\n",
    "                        label_tensor[j,i,self.C]=1\n",
    "                        label_tensor[j,i,self.C+1:self.C+5]=torch.tensor([x_cell,y_cell,w_cell,h_cell])\n",
    "                        label_tensor[j,i,0]=class_id\n",
    "        return  image, label_tensor"
   ],
   "id": "323ce0e8cca64f97",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculo del IoU",
   "id": "4fafb4bf63a3ccd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T02:46:25.316384Z",
     "start_time": "2025-05-09T02:46:25.312445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels):\n",
    "    box1_x1=boxes_preds[0]-boxes_preds[2]/2\n",
    "    box1_y1=boxes_preds[1]-boxes_preds[3]/2\n",
    "    box1_x2=boxes_preds[0]+boxes_preds[2]/2\n",
    "    box1_y2=boxes_preds[1]+boxes_preds[3]/2\n",
    "\n",
    "    box2_x1=boxes_labels[0]-boxes_labels[2]/2\n",
    "    box2_y1=boxes_labels[1]-boxes_labels[3]/2\n",
    "    box2_x2=boxes_labels[0]+boxes_labels[2]/2\n",
    "    box2_y2=boxes_labels[1]+boxes_labels[3]/2\n",
    "\n",
    "    x1=max(box1_x1,box2_x1)\n",
    "    y1=max(box1_y1,box2_y1)\n",
    "    x2=min(box1_x2,box2_x2)\n",
    "    y2=min(box1_y2,box2_y2)\n",
    "\n",
    "    intersection=max(0,x2-x1)*max(0,y2-y1)\n",
    "\n",
    "    box1_area=(box1_x2-box1_x1)*(box1_y2-box1_y1)\n",
    "    box2_area=(box2_x2-box2_x1)*(box2_y2-box2_y1)\n",
    "\n",
    "    union=box1_area+box2_area-intersection+1e-6\n",
    "    return intersection/union"
   ],
   "id": "fd9284781ae765c5",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# YOLOLOSS",
   "id": "4db1d1ce037616f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T02:46:28.595263Z",
     "start_time": "2025-05-09T02:46:28.588804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "class YOLOLoss(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=1, lambda_coords=5,lambda_noobj=0.5 ):\n",
    "        super(YOLOLoss, self).__init__()\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.lambda_coords=lambda_coords\n",
    "        self.lambda_noobj=lambda_noobj\n",
    "        self.mse=nn.MSELoss(reduction='sum')\n",
    "    def forward(self, predictions, target):\n",
    "        N=predictions.size(0)\n",
    "        loss=0\n",
    "        for n in range(N):\n",
    "            for i in range(self.S):\n",
    "                for j in range(self.S):\n",
    "                    pred=predictions[n,i,j]\n",
    "                    truth=target[n,i,j]\n",
    "                    has_obj=truth[self.C]\n",
    "                    if has_obj==1:\n",
    "                        ious=[]\n",
    "                        for b in range(self.B):\n",
    "                            start=self.C+b*5+1\n",
    "                            box_pred=pred[start:start+4]\n",
    "                            box_true=truth[self.C+1:self.C+5]\n",
    "                            iou=intersection_over_union(box_pred,box_true)\n",
    "                            ious.append(iou)\n",
    "                        best_box=torch.argmax(torch.tensor(ious))\n",
    "                        #Coordednadas y confianza del mejor box\n",
    "                        start=self.C+best_box*5\n",
    "                        pred_box=pred[start+1:start+5]\n",
    "                        true_box=truth[self.C+1:self.C+5]\n",
    "\n",
    "                        pred_conf=pred[start]\n",
    "                        true_conf=truth[self.C]\n",
    "                        #perdida de la clase\n",
    "                        loss += self.mse(pred[0:self.C], truth[0:self.C])\n",
    "                        loss+=self.lambda_coords*(self.mse(pred_box,true_box))\n",
    "                        loss+=self.mse(pred_conf,true_conf)\n",
    "                        #Penalizar confianza de los otros boxes\n",
    "                        for b in range(self.B):\n",
    "                            if b !=best_box:\n",
    "                                conf=pred[self.C+b*5]\n",
    "                                loss+=self.lambda_noobj*self.mse(conf,torch.tensor(0.))\n",
    "                    else:\n",
    "                        for b in range(self.B):\n",
    "                            conf=pred[self.C+b*5]\n",
    "                            loss+=self.lambda_noobj*self.mse(conf,torch.tensor(0.))\n",
    "        return loss/N"
   ],
   "id": "c6a1c7fd99dfa2b6",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Entrenamiento",
   "id": "880ad4576e6d4ad4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T02:46:32.187835Z",
     "start_time": "2025-05-09T02:46:32.181880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_yolov1(model,dataset,loss_fn, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", epochs=50, batch_size=16, lr=1e-4, checkpoint_path=\"yolov1_final.path\", save_best=True):\n",
    "    dataloader=DataLoader(dataset,batch_size=batch_size,shuffle=True, drop_last=True)\n",
    "    model=model.to(device)\n",
    "    optimizer=optim.Adam(model.parameters(),lr=lr)\n",
    "    scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=5,gamma=0.5)\n",
    "    best_loss=float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss=0\n",
    "        loop=tqdm(dataloader,leave=False)\n",
    "        for imgs, labels in loop:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            preds=model(imgs)\n",
    "            loss=loss_fn(preds,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss+=loss.item()\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=loss.item(), avg_loss=epoch_loss/(loop.n+1))\n",
    "\n",
    "    avg_loss=epoch_loss/len(dataloader)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]- Loss: {avg_loss:.4f}\")\n",
    "    if save_best and avg_loss < best_loss:\n",
    "        best_loss=avg_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"Nuevo mejor modelo guardado (Loss: {best_loss:.4f})\")\n",
    "    if (epoch+1)%5==0:\n",
    "        ckpt_name=f\"checkpoint_{epoch+1}.pth\"\n",
    "        torch.save(model.state_dict(), ckpt_name)\n",
    "        print(f\"Guardado de checkpoint: {ckpt_name}\")\n",
    "\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Modelo final guardado en: {checkpoint_path}\")\n"
   ],
   "id": "951a48dc0e98da4",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparativos finales",
   "id": "49b2d68172599303"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-09T02:46:36.123847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model=Yolo(s=7,b=2,c=1)\n",
    "loss_fn=YOLOLoss(S=7,B=2,C=1)\n",
    "\n",
    "image_dir=r\"C:\\Users\\Intel\\Desktop\\yolo\\brain-tumor\\train\\images\"\n",
    "label_dir=r\"C:\\Users\\Intel\\Desktop\\yolo\\brain-tumor\\train\\labels\"\n",
    "\n",
    "train_dataset=TumorDataset(img_dir=image_dir,label_dir=label_dir,S=7,B=2,C=1)\n",
    "\n",
    "train_yolov1(model=model,dataset=train_dataset,loss_fn=loss_fn, epochs=50, batch_size=16)"
   ],
   "id": "dbefbb17b85318f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/50]:  89%|████████▉ | 49/55 [08:22<00:59,  9.89s/it, avg_loss=9.26, loss=6.07]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creamos una función de predicción",
   "id": "41a4b5bc8d1eec2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_prediction_on_image(model, image_path, S=7, B=2, C=1, conf_threshold=0.4):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    transform = T.Compose([T.Resize((448, 448)), T.ToTensor()])\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_w, original_h = image.size\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor).squeeze(0).cpu()\n",
    "\n",
    "    best_conf = 0\n",
    "    best_box = None\n",
    "    for i in range(S):\n",
    "        for j in range(S):\n",
    "            cell = output[i, j]\n",
    "            for b in range(B):\n",
    "                conf = cell[C + b * 5]\n",
    "                if conf > best_conf and conf > conf_threshold:\n",
    "                    x_rel, y_rel, w_rel, h_rel = cell[C + b * 5 + 1:C + b * 5 + 5]\n",
    "                    best_conf = conf\n",
    "                    best_box = (j, i, x_rel, y_rel, w_rel, h_rel)\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    if best_box:\n",
    "        j, i, x_cell, y_cell, w, h = best_box\n",
    "        x_center = (j + x_cell) / S * original_w\n",
    "        y_center = (i + y_cell) / S * original_h\n",
    "        width = w * original_w\n",
    "        height = h * original_h\n",
    "\n",
    "        x1 = x_center - width / 2\n",
    "        y1 = y_center - height / 2\n",
    "        x2 = x_center + width / 2\n",
    "        y2 = y_center + height / 2\n",
    "\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
    "        draw.text((x1, y1 - 10), f\"conf: {best_conf:.2f}\", fill=\"red\")\n",
    "    else:\n",
    "        print(\"⚠️ No se detectó ningún objeto con suficiente confianza.\")\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Predicción YOLOv1 - Tumor cerebral\")\n",
    "    plt.show()\n"
   ],
   "id": "865f37a1d5877353"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modelo cargado",
   "id": "5c65c466403ddcb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "24be30e8b709119e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Implementamos",
   "id": "3b348da85dbb71c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "path_test=r\"C:\\Users\\Intel\\Desktop\\yolo\\brain-tumor\\valid\\images\\val_1 (1).jpg\"\n",
    "show_prediction_on_image(model,path_test)"
   ],
   "id": "46a5d3b860338e9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
